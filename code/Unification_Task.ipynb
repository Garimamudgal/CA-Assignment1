{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import csv\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------reading annotation files\n",
    "def read_ann_file(file):\n",
    "    f = open(file,\"r\",encoding=\"utf8\")\n",
    "    ann_Text = f.read()\n",
    "    return ann_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------reading labels  files\n",
    "file =\"data/labels.tsv\"\n",
    "labels = open(file,\"r\",encoding=\"utf8\").read()\n",
    "\n",
    "def get_conf_bias(file):\n",
    "    for item in labels.split(\"\\n\"):\n",
    "        if file in item :\n",
    "            confirmation_bias = item.strip().split()\n",
    "            if confirmation_bias[1] == \"negative\":\n",
    "                return(\"false\")\n",
    "            elif confirmation_bias[1] ==\"positive\":\n",
    "                return(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------getting paragraph text and anotation status\n",
    "def get_Paragraphs(essay_no):\n",
    "    with open(\"data/data-tokenized.tsv\") as tsvfile:\n",
    "        reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
    "        for row in reader:\n",
    "            Paragraph_dict = {\"text\": \"\" , \"sufficient\" : True}\n",
    "            if row['ESSAY'] == str(essay_no):\n",
    "                Paragraph_dict['text'] = row['TEXT']\n",
    "                if row['ANNOTATION'] == 'insufficient':\n",
    "                      Paragraph_dict['sufficient'] = False\n",
    "                elif row['ANNOTATION'] == '' :\n",
    "                      Paragraph_dict['sufficient'] = True\n",
    "            unified_file.append(Paragraph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------reading text files\n",
    "def get_text(file):\n",
    "    essay_Text =open(file,\"r\",encoding=\"utf8\").read()\n",
    "#     print(text)\n",
    "    return essay_Text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_file = []\n",
    "ann_list = []\n",
    "# confirmation_dict = {\"confirmation_bias\" : True }\n",
    "counter = 1\n",
    "# dict_para = {'text':\"\",'sufficient' : True }\n",
    "\n",
    "for file in glob.glob(\"data/brat-project-final/essay*.ann\"):\n",
    "\n",
    "#------------------------------------ Declaring variables -------------------------------\n",
    "    id_dict ={'id': 0 , \"text\" : \"\"}\n",
    "    id_dict[\"major_claim\"] = []\n",
    "#     major_claim_dict = {'span' : 0 , \"text\": \"\"}\n",
    "    id_dict[\"claims\"] = []\n",
    "#     claims_dict = {'span' : 0 , \"text\": \"\"}\n",
    "    id_dict[\"premises\"] =[]\n",
    "#     premises_dict = {'span' : 0 , \"text\": \"\"}\n",
    "    id_dict[\"paragraphs\"] = []\n",
    "    \n",
    "#------------------------------------ Declaring variables Ends -------------------------------\n",
    "    ann_text = read_ann_file(file)\n",
    "    ann_file_name = file\n",
    "    txt_file_name = ann_file_name.replace(\"ann\",\"txt\")\n",
    "    id_dict['id'] = counter\n",
    "    id_dict['text'] = get_text(txt_file_name)\n",
    "    for item in ann_text.split(\"\\n\"):  # Elements collection from each Annotation file.\n",
    "        major_claim_dict = {'span' : 0 , \"text\": \"\"}\n",
    "        claims_dict = {'span' : 0 , \"text\": \"\"}\n",
    "        premises_dict = {'span' : 0 , \"text\": \"\"}\n",
    "        # ---------------------------- Collecting Major claim--------------------------------\n",
    "        if \"MajorClaim\" in item :\n",
    "            ann_list = item.strip()\n",
    "            ann_list_words = ann_list.split()\n",
    "            MajorClaim=' '.join(ann_list_words[4:])\n",
    "            MC_Span = ann_list_words[2:4]\n",
    "            MC_Span_int = list(map(int, MC_Span))\n",
    "            major_claim_dict['span'] = MC_Span_int\n",
    "            major_claim_dict['text'] = MajorClaim\n",
    "            id_dict['major_claim'].append(major_claim_dict) \n",
    "            # ---------------------------- Collecting Claims----------------------------------\n",
    "        if \"Claim\" in item and \"MajorClaim\" not in item :\n",
    "            ann_claim_list = item.strip()\n",
    "            ann_claim_words = ann_claim_list.split()\n",
    "            Claim=' '.join(ann_claim_words[4:])\n",
    "            C_Span = list(map(int,ann_claim_words[2:4]))\n",
    "            claims_dict['span'] = C_Span\n",
    "            claims_dict['text'] = Claim\n",
    "            id_dict['claims'].append(claims_dict)\n",
    "             # ---------------------------- Collecting Claims----------------------------------\n",
    "        if \"Premise\" in item :\n",
    "            ann_premise_list = item.strip()\n",
    "            ann_premise_words = ann_premise_list.split()\n",
    "            Premise_text=' '.join(ann_premise_words[4:])\n",
    "            P_Span = list(map(int,ann_premise_words[2:4]))\n",
    "            premises_dict['span'] = P_Span\n",
    "            premises_dict['text'] = Premise_text\n",
    "            id_dict['premises'].append(premises_dict)   \n",
    "    #--------------------------exiting the for loop for single file parsing --------------------------    \n",
    "    \n",
    "        # -----------getting the confirmation bias. ------------------------\n",
    "    conf_file_name=file.replace(\"data/brat-project-final\\essay\",\"essay\").replace(\".ann\",\"\")\n",
    "    confirmation_bias = get_conf_bias(conf_file_name)\n",
    "    id_dict['confirmation_bias'] = confirmation_bias\n",
    "    # -----------getting the paragraphs------------------------\n",
    "    \n",
    "    with open(\"data/data-tokenized.tsv\") as tsvfile:\n",
    "        reader = csv.DictReader(tsvfile, dialect='excel-tab')\n",
    "        for row in reader:\n",
    "            Paragraph_dict = {\"text\": \"\" , \"sufficient\" : True}\n",
    "            if row['ESSAY'] == str(counter):\n",
    "                Paragraph_dict['text'] = row['TEXT']\n",
    "                if row['ANNOTATION'] == 'insufficient':\n",
    "                    Paragraph_dict['sufficient'] = False\n",
    "                    id_dict['paragraphs'].append(Paragraph_dict)\n",
    "                elif row['ANNOTATION'] == '' :\n",
    "                    Paragraph_dict['sufficient'] = True\n",
    "                    id_dict['paragraphs'].append(Paragraph_dict)\n",
    "            \n",
    "\n",
    "    unified_file.append(id_dict)\n",
    "    with open(\"just_id.json\", \"w\") as outfile:\n",
    "        json.dump(unified_file, outfile, indent=4)\n",
    "    counter = counter+1  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
